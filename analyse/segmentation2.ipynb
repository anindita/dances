{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMfA4KjLUsHDxjIbyeEU0pA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anindita/dances/blob/main/analyse/segmentation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92CPHaDEm3nB"
      },
      "source": [
        "# Segmentation 2\n",
        "\n",
        "This has been modified by code written by [tugstugi](https://github.com/tugstugi/dl-colab-notebooks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxBN9o3pukMz"
      },
      "source": [
        "YOUTUBE_ID = 'sb82tVOq2dY'\n",
        "\n",
        "!pip install -q youtube-dl\n",
        "!youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
        "!ffmpeg -y -loglevel info -i youtube.mp4 -ss 00:00:58 -t 2 video.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7e85FDBvSjX"
      },
      "source": [
        "!mkdir images\n",
        "video_size = (320,240)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJv0lX5umDH"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "  \n",
        "\n",
        "cam = cv2.VideoCapture(\"video.mp4\")\n",
        "currentframe = 0\n",
        "kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "  \n",
        "while(True):\n",
        "    ret,frame = cam.read()\n",
        "  \n",
        "    if ret:\n",
        "        name = '/content/images/' + str(currentframe) + '.jpg'\n",
        "        print ('Creating...' + name)\n",
        "  \n",
        "        frame = cv2.resize(frame, (1280,720))\n",
        "        frame = frame[0:720, 160:1120]\n",
        "        frame = cv2.resize(frame, video_size)\n",
        "        frame = cv2.filter2D(frame, -1, kernel)\n",
        "        cv2.imwrite(name, frame)\n",
        "\n",
        "        currentframe += 1\n",
        "    else:\n",
        "        break\n",
        "  \n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVn0GLduutTV"
      },
      "source": [
        "# Prepare seg model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX_2ixLMt68j"
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CSAILVision/semantic-segmentation-pytorch.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install dependencies\n",
        "  !git clone -q $git_repo_url\n",
        "  #!cd $project_name && pip install -q -r requirement.txt\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "models = f'{project_name}/mit_semseg/'\n",
        "sys.path.append(models)\n",
        "\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81qlCIH2FfbE"
      },
      "source": [
        "ENCODER_NAME = 'resnet101'\n",
        "DECODER_NAME = 'upernet'\n",
        "PRETRAINED_ENCODER_MODEL_URL = 'http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-%s-%s/encoder_epoch_50.pth' % (ENCODER_NAME, DECODER_NAME)\n",
        "PRETRAINED_DECODER_MODEL_URL = 'http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-%s-%s/decoder_epoch_50.pth' % (ENCODER_NAME, DECODER_NAME)\n",
        "\n",
        "pretrained_encoder_file = basename(PRETRAINED_ENCODER_MODEL_URL)\n",
        "if not exists(pretrained_encoder_file):\n",
        "  !wget -q $PRETRAINED_ENCODER_MODEL_URL\n",
        "pretrained_decoder_file = basename(PRETRAINED_DECODER_MODEL_URL)\n",
        "if not exists(pretrained_decoder_file):\n",
        "  !wget -q $PRETRAINED_DECODER_MODEL_URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8xpgU-auznw"
      },
      "source": [
        "from types import SimpleNamespace\n",
        "import torch\n",
        "from models import ModelBuilder, SegmentationModule\n",
        "from dataset import TestDataset\n",
        "from utils import colorEncode\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# options\n",
        "options = SimpleNamespace(fc_dim=2048,\n",
        "                          num_class=150,\n",
        "                          imgSizes = [300, 400, 500, 600],\n",
        "                          imgMaxSize=1000,\n",
        "                          padding_constant=8,\n",
        "                          segm_downsampling_rate=8)\n",
        "\n",
        "# create model\n",
        "builder = ModelBuilder()\n",
        "net_encoder = builder.build_encoder(arch=ENCODER_NAME, weights=pretrained_encoder_file,\n",
        "                                    fc_dim=options.fc_dim)\n",
        "net_decoder = builder.build_decoder(arch=DECODER_NAME, weights=pretrained_decoder_file,\n",
        "                                    fc_dim=options.fc_dim, num_class=options.num_class, use_softmax=True)\n",
        "segmentation_module = SegmentationModule(net_encoder, net_decoder, torch.nn.NLLLoss(ignore_index=-1))\n",
        "segmentation_module = segmentation_module.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  segmentation_module = segmentation_module.cuda()\n",
        "\n",
        "# test on a given image\n",
        "def test(test_image_name):\n",
        "  dataset_test = TestDataset([{'fpath_img': test_image_name}], options, max_sample=-1)\n",
        "  \n",
        "  batch_data = dataset_test[0]\n",
        "  segSize = (batch_data['img_ori'].shape[0], batch_data['img_ori'].shape[1])\n",
        "  img_resized_list = batch_data['img_data']\n",
        "  \n",
        "  scores = torch.zeros(1, options.num_class, segSize[0], segSize[1])\n",
        "  if torch.cuda.is_available():\n",
        "    scores = scores.cuda()\n",
        "\n",
        "  for img in img_resized_list:\n",
        "    feed_dict = batch_data.copy()\n",
        "    feed_dict['img_data'] = img\n",
        "    del feed_dict['img_ori']\n",
        "    del feed_dict['info']\n",
        "    if torch.cuda.is_available():\n",
        "      feed_dict = {k: o.cuda() for k, o in feed_dict.items()}\n",
        "\n",
        "    # forward pass\n",
        "    pred_tmp = segmentation_module(feed_dict, segSize=segSize)\n",
        "    scores = scores + pred_tmp / len(options.imgSizes)\n",
        "\n",
        "    _, pred = torch.max(scores, dim=1)\n",
        "    return pred.squeeze(0).cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIRTje5cu3H4"
      },
      "source": [
        "# Trial image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o47QPLKu0Kh"
      },
      "source": [
        "def segment(image_file):\n",
        "  t = time.time()\n",
        "  pred = test(image_file)\n",
        "  print(\"executed in %.3fs\" % (time.time()-t))\n",
        "\n",
        "  pred_color = colorEncode(pred, loadmat(os.path.join(project_name, 'data/color150.mat'))['colors'])\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.imshow(pred_color)\n",
        "\n",
        "arr = os.listdir('/content/images')\n",
        "for f in arr:\n",
        "  segment(f'/content/images/{f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
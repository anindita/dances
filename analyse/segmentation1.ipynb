{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabV3",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO5/SymQyYVT9z9CSOQKOgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anindita/dances/blob/main/analyse/segmentation1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6g3L8C9mnZD"
      },
      "source": [
        "# Segmentation 1\n",
        "\n",
        "This has been modified by code written by [tugstugi](https://github.com/tugstugi/dl-colab-notebooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYSU2BSkRvI"
      },
      "source": [
        "# Make images from video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIPT_i12fJCp"
      },
      "source": [
        "YOUTUBE_ID = 'Y4ARBzok9aU'\n",
        "\n",
        "!pip install -q youtube-dl\n",
        "!youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
        "!ffmpeg -y -loglevel info -i youtube.mp4 -ss 00:05:28 -t 2 video.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g17YOD5wnmwD"
      },
      "source": [
        "!mkdir images\n",
        "\n",
        "video_size=(320, 240)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWRLQqUTkYIx"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "  \n",
        "\n",
        "cam = cv2.VideoCapture(\"video.mp4\")\n",
        "currentframe = 0\n",
        "kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "  \n",
        "while(True):\n",
        "    ret,frame = cam.read()\n",
        "  \n",
        "    if ret:\n",
        "        name = '/content/images/' + str(currentframe) + '.jpg'\n",
        "        print ('Creating...' + name)\n",
        "  \n",
        "        frame = cv2.resize(frame, (1280,720))\n",
        "        frame = frame[0:720, 160:1120]\n",
        "        frame = cv2.resize(frame, video_size)\n",
        "        frame = cv2.filter2D(frame, -1, kernel)\n",
        "        cv2.imwrite(name, frame)\n",
        "\n",
        "        currentframe += 1\n",
        "    else:\n",
        "        break\n",
        "  \n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7PlkxovkdKR"
      },
      "source": [
        "# Try to segment diver from image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6s9fADdkncL"
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "import random\n",
        "import PIL\n",
        "import torchvision\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.set_grad_enabled(False)\n",
        "  \n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "\n",
        "model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
        "model = model.eval().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weT34MoroasZ"
      },
      "source": [
        "\n",
        "def segment(image_file):\n",
        "  image = PIL.Image.open(image_file)\n",
        "  image_tensor = torchvision.transforms.functional.to_tensor(image).cuda()\n",
        "  output = model(image_tensor.unsqueeze(0))\n",
        "\n",
        "\n",
        "  # visualization code copied from: https://github.com/fregu856/deeplabv3/blob/master/visualization/run_on_seq.py\n",
        "  #\n",
        "  outputs = output['out'].cpu().numpy() # (shape: (batch_size, num_classes, img_h, img_w))\n",
        "  pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, img_h, img_w))\n",
        "  pred_label_imgs = pred_label_imgs.astype(np.uint8)\n",
        "\n",
        "  label_names = ['__background__', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'] \n",
        "  def label_img_to_color(img):\n",
        "      label_to_color = {\n",
        "          0: [128, 64,128], 1: [244, 35,232], 2: [ 70, 70, 70], 3: [102,102,156],\n",
        "          4: [190,153,153], 5: [153,153,153], 6: [250,170, 30], 7: [220,220,  0],\n",
        "          8: [107,142, 35], 9: [152,251,152], 10: [ 70,130,180], 11: [220, 20, 60],\n",
        "          12: [255,  0,  0], 13: [  0,  0,142], 14: [  0,  0, 70], 15: [  0, 60,100],\n",
        "          16: [  0, 80,100], 17: [  0,  0,230], 18: [119, 11, 32], 19: [81,  0, 81]\n",
        "          }\n",
        "\n",
        "      img_height, img_width = img.shape\n",
        "      img_color = np.zeros((img_height, img_width, 3))\n",
        "      for row in range(img_height):\n",
        "          for col in range(img_width):\n",
        "              label = img[row, col]\n",
        "              img_color[row, col] = np.array(label_to_color[label])\n",
        "\n",
        "      return img_color\n",
        "\n",
        "\n",
        "  i = 0\n",
        "  pred_label_img = pred_label_imgs[i] # (shape: (img_h, img_w))\n",
        "  img = image_tensor #imgs[i] # (shape: (3, img_h, img_w))\n",
        "\n",
        "  img = img.data.cpu().numpy()\n",
        "  img = np.transpose(img, (1, 2, 0)) # (shape: (img_h, img_w, 3))\n",
        "  img = img*np.array([0.229, 0.224, 0.225])\n",
        "  img = img + np.array([0.485, 0.456, 0.406])\n",
        "  img = img*255.0\n",
        "  img = img.astype(np.uint8)\n",
        "\n",
        "  pred_label_img_color = label_img_to_color(pred_label_img)\n",
        "  overlayed_img = 0.35*img + 0.65*pred_label_img_color\n",
        "  overlayed_img = overlayed_img.astype(np.uint8)\n",
        "\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.imshow(overlayed_img)\n",
        "\n",
        "arr = os.listdir('/content/images')\n",
        "for f in arr:\n",
        "  segment(f'/content/images/{f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}